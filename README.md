# MCP Telegram Bot

Telegram-бот с расширенной поддержкой различных больших языковых моделей (LLM) и интеграцией с Model Context Protocol (MCP) для динамического расширения функционала.

## Оглавление

-   [Функционал](#функционал)
-   [Установка](#установка)
-   [Конфигурация MCP серверов](#конфигурация-mcp-серверов)
-   [Команды](#команды)
-   [TODO](#todo)
-   [Вклад](#вклад)
-   [Лицензия](#лицензия)
-   [Контакты](#контакты)

## Функционал

*   **Поддержка различных LLM:** Легко переключайтесь между OpenAI, Google Gemini, Ollama и другими моделями.
*   **Интеграция с Model Context Protocol (MCP):** Расширяйте возможности бота, подключая внешние MCP сервера, предоставляющие специализированные инструменты и ресурсы.
*   **Поддержка различных типов MCP клиентов:** Работа с HTTP, stdio (через jsonrpyc) и SSE-based MCP серверами.
*   **Обработка изображений:** Бот может обрабатывать изображения, отправленные пользователями.
*   **Обработка голосовых сообщений и документов:** Поддержка голосовых сообщений и документов, отправленных пользователями.
*   **Гибкая конфигурация:** Все настройки, включая токены API и параметры LLM, управляются через файл `.env`.

## Установка

Для запуска бота выполните следующие шаги:

1.  **Клонируйте репозиторий:**
    ```bash
    git clone https://github.com/MrFadzay/MCP-Telegram-Bot.git
    cd MCP-Telegram-Bot
    ```

2.  **Создайте и активируйте виртуальное окружение:**

    *   **Windows:**
        ```bash
        python -m venv venv
        .\venv\Scripts\activate
        ```
    *   **Linux/macOS:**
        ```bash
        python3 -m venv venv
        source venv/bin/activate
        ```

3.  **Установите зависимости:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Настройте переменные окружения:**
    *   Создайте файл `.env` в корневой директории проекта, скопировав содержимое из `.env.example`.
    *   Добавьте ваш токен Telegram бота (`TELEGRAM_TOKEN`) и другие необходимые ключи API для LLM (например, `OPENAI_API_KEY`, `GOOGLE_API_KEY`).

5.  **Запустите бота:**
    ```bash
    python main.py
    ```

## Конфигурация MCP серверов

Model Context Protocol (MCP) позволяет расширять функционал бота, подключая внешние сервера, которые предоставляют дополнительные инструменты и ресурсы.

Для настройки MCP серверов отредактируйте файл `config/mcp_servers.json`.

Пример `config/mcp_servers.json`:

```json
{
  "mcpServers": {
    "weather_api": {
      "type": "http",
      "url": "http://localhost:8000/weather",
      "description": "Сервер для получения информации о погоде"
    },
    "search_tools": {
      "type": "stdio",
      "command": "uvx",
      "args": ["search-tools-mcp-server@latest"],
      "env": {
        "FASTMCP_LOG_LEVEL": "ERROR"
      },
      "description": "Инструменты для поиска информации"
    }
  }
}
```

*   Ключи (например, `weather_api`, `search_tools`) — это уникальные имена, которые будут использоваться в командах бота для обращения к конкретному MCP серверу.
*   `type` — тип MCP сервера: `http`, `stdio` или `sse`.
*   `url` — адрес MCP сервера (для HTTP и SSE серверов).
*   `command` и `args` — команда и аргументы для запуска stdio-сервера.
*   `env` — переменные окружения для stdio-сервера.
*   `description` — описание сервера.

## Команды

### Основные команды
*   `/start` - Начать общение с ботом и получить приветственное сообщение.
*   `/help` - Отобразить список доступных команд и краткое описание.

### Настройки
*   `/select` - Выбрать активный API клиент (LLM провайдера) и модель для общения.
*   `/settings` - Показать все настройки пользователя.

### Инструменты
*   `/tools` - Показать список доступных MCP инструментов.

### История диалогов
*   `/history` - Показать статистику текущей сессии и последние сообщения.
*   `/clear` - Очистить историю диалога и начать новую сессию.

## Инициализация базы данных

Перед первым запуском бота необходимо инициализировать базу данных:

```bash
python migrate.py init
```

Для сброса базы данных (удаление всех данных):
```bash
python migrate.py reset
```

Проверка статуса базы данных:
```bash
python migrate.py status
```

## Статус разработки

Бот функционален со следующими реализованными возможностями:
- ✅ Поддержка нескольких LLM (OpenAI, Google Gemini, Ollama)
- ✅ Интеграция MCP с HTTP, stdio и SSE клиентами
- ✅ Персистентность базы данных для настроек пользователей и истории чатов
- ✅ Управление контекстом разговора с HistoryService
- ✅ Пользовательские предпочтения и управление сессиями

## TODO

*   Добавить поддержку других LLM конечных точек (endpoints)
*   Улучшить обработку ошибок и логирование
*   Расширить функциональность MCP клиента с улучшенным восстановлением после ошибок
*   Добавить расширенные функции управления разговорами

## Вклад

Мы приветствуем любой вклад в развитие проекта! Если вы хотите помочь, пожалуйста, ознакомьтесь с файлом `CONTRIBUTING.md` (если он будет создан) или просто создайте Pull Request.

## Лицензия

Этот проект распространяется под лицензией [MIT License](LICENSE).

## Контакты

Если у вас есть вопросы или предложения, вы можете связаться с разработчиком:

*   GitHub: [MrFadzay](https://github.com/MrFadzay)
*   Telegram: [@Fadzay](https://t.me/Fadzay)